{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from louisdataset import MyDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_DictX(full_dataframe, Y): # e.g. create_dict_list(dataset_train.df)\n",
    "    \n",
    "    # temporary fix: can put the variables as arguments\n",
    "    DictX = full_dataframe.copy()\n",
    "    del DictX['First Name']\n",
    "    del DictX['Last Name']\n",
    "    del DictX['Birthday']\n",
    "    del DictX['Index'] \n",
    "    del DictX[Y]\n",
    "    return DictX\n",
    "\n",
    "def get_dummies(full_dataframe, variable):\n",
    "    Dict = {variable:full_dataframe[variable]}.copy()\n",
    "    Categories = list(set(Dict[variable])) \n",
    "    for i in Categories: \n",
    "        Dict[i] = [(element == i)*1 for element in Dict[variable]]\n",
    "    del Dict[variable]\n",
    "    return Dict\n",
    "\n",
    "def get_Y(full_dict, Y):\n",
    "    return np.array(full_dict[Y].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import optimize "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data_raw = pd.read_csv('./resources/dataset_train.csv')\n",
    "data_raw.head()\n",
    "# data_raw.groupby(by=['Hogwarts House']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict_list(dict_dict): # on self.df\n",
    "    newDict = dict.fromkeys(dict_dict.keys())\n",
    "    for i in dict_dict.keys():\n",
    "        newDict[i] = list(dict_dict[i].values())\n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for a given feature \n",
    "def one_hot_encoder(dataframe, column_to_encode) : \n",
    "    Encoded_Dict = dataframe.copy()\n",
    "    NewCategories = list(set(Encoded_Dict[column_to_encode]))\n",
    "    NewCategories.pop() # remove the last element \n",
    "    for i in NewCategories: \n",
    "        Encoded_Dict[i] = [(element == i)*1 for element in Encoded_Dict[column_to_encode]]\n",
    "    del Encoded_Dict[column_to_encode]\n",
    "    return Encoded_Dict\n",
    "\n",
    "# for every feature \n",
    "def full_one_hot_encoder(dataframe) : # dataframe = NewDict\n",
    "    keys_str = [keys for keys in dataframe.keys() if type(list(dataframe[keys])[0]) == str]\n",
    "    Full_Dict = dataframe\n",
    "    for key in keys_str:\n",
    "        Full_Dict = one_hot_encoder(Full_Dict, key)\n",
    "    return np.column_stack(list(Full_Dict.values())) # return the dictionary as a matrix for the LogReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from louisdataset import MyDataSet\n",
    "\n",
    "name_Y = 'Hogwarts House'\n",
    "\n",
    "dataset_train = MyDataSet().read_csv('resources/dataset_train.csv')\n",
    "NewDict = dataset_train.dict_list()\n",
    "\n",
    "# getting X\n",
    "DictX = get_DictX(NewDict, name_Y)\n",
    "X = full_one_hot_encoder(DictX)\n",
    "\n",
    "# getting Y\n",
    "SubDict = get_dummies(NewDict, 'Hogwarts House')\n",
    "Y = get_Y(SubDict, 'Gryffindor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_train = MyDataSet().read_csv('resources/dataset_train.csv')\n",
    "# dataset_train.describe()\n",
    "\n",
    "NewDict = create_dict_list(dataset_train.df)\n",
    "name_Y = 'Hogwarts House'\n",
    "\n",
    "# getting X\n",
    "DictX = get_DictX(NewDict, name_Y)\n",
    "X = full_one_hot_encoder(DictX)\n",
    "\n",
    "# getting Y\n",
    "SubDict = get_dummies(NewDict, 'Hogwarts House')\n",
    "Y = get_Y(SubDict, 'Gryffindor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n",
      "(1600, 14)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neg_loglikelihood(beta, Y, X):\n",
    "    # sum without NAs\n",
    "    return -np.nansum(Y*np.matmul(X,beta) - np.log(1+np.exp(np.matmul(X,beta))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_LogReg_coef(Y_train, X_train):\n",
    "    n, d = X_train.shape\n",
    "    init_w = np.zeros(d)\n",
    "    res = optimize.minimize(neg_loglikelihood,init_w, method = 'BFGS', args = (Y_train,X_train))\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louislimnavong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/louislimnavong/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py:643: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Users/louislimnavong/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-6.73873258e-04,  1.94102649e-02,  2.10344212e+00, -3.14179045e-02,\n",
       "       -1.80698276e+00, -2.46670581e-02,  2.71721871e-01, -2.48479360e+00,\n",
       "       -1.82458665e-01, -1.67631934e+00,  8.22153813e-02, -4.34301110e-01,\n",
       "       -3.70778470e-01, -8.27701406e-01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_LogReg_coef(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
